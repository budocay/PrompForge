# ğŸ³ PromptForge - Guide de DÃ©ploiement Docker

Guide complet pour lancer PromptForge avec Docker, incluant l'interface web Gradio et Ollama.

---

## ğŸ“‹ Table des matiÃ¨res

1. [PrÃ©requis](#-prÃ©requis)
2. [Installation Rapide (5 minutes)](#-installation-rapide)
3. [Installation DÃ©taillÃ©e](#-installation-dÃ©taillÃ©e)
4. [Configuration](#-configuration)
5. [Utilisation](#-utilisation)
6. [Changer de ModÃ¨le Ollama](#-changer-de-modÃ¨le-ollama)
7. [DÃ©pannage](#-dÃ©pannage)
8. [Commandes Utiles](#-commandes-utiles)

---

## ğŸ”§ PrÃ©requis

### Minimum requis

| Composant | Version minimum | VÃ©rification |
|-----------|-----------------|--------------|
| Docker | 20.10+ | `docker --version` |
| Docker Compose | 2.0+ | `docker compose version` |
| RAM | 8 GB | - |
| Disque | 10 GB libre | Pour les modÃ¨les Ollama |

### Optionnel (recommandÃ©)

| Composant | Pour quoi faire |
|-----------|-----------------|
| GPU NVIDIA | AccÃ©lÃ©rer Ollama (10x plus rapide) |
| NVIDIA Driver | 525+ |
| NVIDIA Container Toolkit | Support GPU dans Docker |

### VÃ©rifier Docker

```bash
# VÃ©rifier Docker
docker --version
# Docker version 24.0.0 ou supÃ©rieur

# VÃ©rifier Docker Compose
docker compose version
# Docker Compose version v2.20.0 ou supÃ©rieur
```

### Installer NVIDIA Container Toolkit (optionnel, pour GPU)

```bash
# Ubuntu/Debian
curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \
  sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
  sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
sudo apt-get update
sudo apt-get install -y nvidia-container-toolkit
sudo systemctl restart docker

# VÃ©rifier
docker run --rm --gpus all nvidia/cuda:12.0-base nvidia-smi
```

---

## ğŸš€ Installation Rapide

### Avec GPU NVIDIA

```bash
# 1. Extraire le projet
unzip promptforge.zip -d promptforge
cd promptforge

# 2. CrÃ©er le dossier de donnÃ©es (IMPORTANT pour la persistance!)
mkdir -p ./data/projects

# 3. Lancer tout (Ollama + Interface Web)
docker compose up -d

# 4. Attendre que le modÃ¨le soit tÃ©lÃ©chargÃ© (~2-5 min)
docker compose logs -f ollama-pull

# 5. Ouvrir l'interface
# http://localhost:7860
```

### Sans GPU (CPU uniquement)

```bash
# 1. Extraire le projet
unzip promptforge.zip -d promptforge
cd promptforge

# 2. CrÃ©er le dossier de donnÃ©es (IMPORTANT!)
mkdir -p ./data/projects

# 3. Lancer avec le fichier CPU
docker compose -f docker-compose.cpu.yml up -d

# 4. Attendre le tÃ©lÃ©chargement du modÃ¨le
docker compose -f docker-compose.cpu.yml logs -f ollama-pull

# 5. Ouvrir l'interface
# http://localhost:7860
```

---

## ğŸ“¦ Installation DÃ©taillÃ©e

### Ã‰tape 1 : Extraire le projet

```bash
# CrÃ©er un dossier
mkdir -p ~/promptforge
cd ~/promptforge

# Extraire
unzip /chemin/vers/promptforge.zip -d .

# VÃ©rifier la structure
ls -la
# Vous devez voir: docker-compose.yml, Dockerfile.web, promptforge/, etc.
```

### Ã‰tape 2 : Construire les images Docker

```bash
# Construire l'image de l'interface web
docker compose build promptforge-web

# VÃ©rifier
docker images | grep promptforge
```

### Ã‰tape 3 : DÃ©marrer Ollama

```bash
# DÃ©marrer uniquement Ollama d'abord
docker compose up -d ollama

# VÃ©rifier qu'il est healthy
docker compose ps
# ollama devrait Ãªtre "healthy" aprÃ¨s ~60 secondes
```

### Ã‰tape 4 : TÃ©lÃ©charger le modÃ¨le LLM

```bash
# MÃ©thode 1: Via le service automatique
docker compose up ollama-pull

# MÃ©thode 2: Manuellement
docker compose exec ollama ollama pull llama3.1

# VÃ©rifier les modÃ¨les installÃ©s
docker compose exec ollama ollama list
```

### Ã‰tape 5 : DÃ©marrer l'interface web

```bash
# DÃ©marrer l'interface
docker compose up -d promptforge-web

# VÃ©rifier les logs
docker compose logs -f promptforge-web

# Vous devez voir:
# Running on local URL:  http://0.0.0.0:7860
```

### Ã‰tape 6 : AccÃ©der Ã  l'interface

Ouvrez votre navigateur Ã  l'adresse :

ğŸŒ **http://localhost:7860**

---

## âš™ï¸ Configuration

### Variables d'environnement

| Variable | Par dÃ©faut | Description |
|----------|------------|-------------|
| `OLLAMA_HOST` | `http://ollama:11434` | URL d'Ollama |
| `GRADIO_SERVER_NAME` | `0.0.0.0` | Adresse d'Ã©coute |
| `GRADIO_SERVER_PORT` | `7860` | Port de l'interface |

### Changer le port de l'interface

Modifier `docker-compose.yml` :

```yaml
promptforge-web:
  ports:
    - "8080:7860"  # Interface sur le port 8080
```

### Persister les donnÃ©es

Les donnÃ©es sont stockÃ©es dans :

| Chemin local | Chemin container | Description |
|--------------|------------------|-------------|
| `./data/` | `/data/` | Base de donnÃ©es + projets crÃ©Ã©s |
| `./data/projects/` | `/data/projects/` | Projets crÃ©Ã©s via l'interface |
| `./data/promptforge.db` | `/data/promptforge.db` | Historique, config |
| Volume `ollama-data` | `/root/.ollama` | ModÃ¨les Ollama tÃ©lÃ©chargÃ©s |

**âš ï¸ Important:** CrÃ©ez le dossier `data` avant le premier lancement pour Ã©viter les problÃ¨mes de permissions :

```bash
mkdir -p ./data/projects
```

**Sauvegarder vos donnÃ©es:**

```bash
# Sauvegarder tout
tar -czvf promptforge-backup.tar.gz ./data

# Restaurer
tar -xzvf promptforge-backup.tar.gz
```

---

## ğŸ® Utilisation

### Interface Web

1. **Onglet "âœ¨ Reformater"**
   - SÃ©lectionner un projet
   - Choisir le profil cible (Claude, GPT, Gemini...)
   - Entrer votre prompt brut
   - Cliquer sur "ğŸš€ Reformater"
   - Voir la recommandation de modÃ¨le

2. **Onglet "ğŸ“ Projets"**
   - CrÃ©er un nouveau projet
   - Uploader un fichier `.md` de configuration
   - Ou Ã©crire la config manuellement

3. **Onglet "ğŸ“œ Historique"**
   - Voir les reformatages passÃ©s
   - Filtrer par projet

4. **Onglet "ğŸ’° Comparaison"**
   - Comparer les prix des modÃ¨les
   - Calculer les coÃ»ts estimÃ©s

### CrÃ©er un projet

1. Aller dans l'onglet "ğŸ“ Projets"
2. Entrer le nom du projet (ex: `mon-api`)
3. Uploader un fichier `.md` ou Ã©crire :

```markdown
# Mon Projet API

## Stack
- Python 3.12
- FastAPI
- PostgreSQL
- Redis

## Structure
- src/api/ - Endpoints
- src/models/ - ModÃ¨les SQLAlchemy
- src/services/ - Logique mÃ©tier

## Conventions
- snake_case pour les variables
- Type hints obligatoires
- Docstrings Google style
```

4. Cliquer sur "ğŸ’¾ Sauvegarder"

---

## ğŸ”„ Changer de ModÃ¨le Ollama

### ModÃ¨les recommandÃ©s pour le reformatage

| ModÃ¨le | Taille | RAM requise | Commande |
|--------|--------|-------------|----------|
| `llama3.2:3b` | 2 GB | 4 GB | Ultra-lÃ©ger, rapide |
| `llama3.1:8b` | 4.7 GB | 8 GB | **RecommandÃ©** |
| `mistral:7b` | 4.1 GB | 8 GB | Rapide, fiable |
| `qwen2.5-coder:7b` | 4.7 GB | 8 GB | Excellent pour code |
| `llama3.3:70b` | 40 GB | 48 GB | Premium (GPU requis) |

### Installer un nouveau modÃ¨le

```bash
# TÃ©lÃ©charger un modÃ¨le
docker compose exec ollama ollama pull mistral:7b

# Lister les modÃ¨les
docker compose exec ollama ollama list

# Supprimer un modÃ¨le (libÃ©rer de l'espace)
docker compose exec ollama ollama rm llama3.1
```

### Changer le modÃ¨le par dÃ©faut

Modifier `docker-compose.yml` dans la section `ollama-pull` :

```yaml
ollama-pull:
  command:
    - |
      echo "Pulling mistral model..."
      ollama pull mistral:7b
      echo "Model ready!"
```

Ou modifier le code dans `promptforge/providers.py` :

```python
@dataclass
class OllamaConfig:
    host: str = "http://localhost:11434"
    model: str = "mistral:7b"  # Changer ici
```

---

## ğŸ”§ DÃ©pannage

### ProblÃ¨me : "Mes projets disparaissent aprÃ¨s rebuild"

C'est un problÃ¨me de persistance des volumes Docker.

```bash
# 1. VÃ©rifier que le dossier data existe
ls -la ./data/

# 2. Si vide ou inexistant, le crÃ©er
mkdir -p ./data/projects

# 3. VÃ©rifier les permissions
chmod -R 755 ./data

# 4. Relancer sans rebuild
docker compose up -d
```

**Note:** Utilisez `docker compose up -d` (sans `--build`) pour conserver les donnÃ©es. Utilisez `--build` uniquement quand vous modifiez le code.

### ProblÃ¨me : "Ollama non disponible"

```bash
# VÃ©rifier qu'Ollama tourne
docker compose ps

# Si "unhealthy", voir les logs
docker compose logs ollama

# RedÃ©marrer
docker compose restart ollama
```

### ProblÃ¨me : "Le modÃ¨le n'est pas tÃ©lÃ©chargÃ©"

```bash
# TÃ©lÃ©charger manuellement
docker compose exec ollama ollama pull llama3.1

# VÃ©rifier
docker compose exec ollama ollama list
```

### ProblÃ¨me : "GPU non dÃ©tectÃ©"

```bash
# VÃ©rifier NVIDIA
nvidia-smi

# VÃ©rifier Docker GPU
docker run --rm --gpus all nvidia/cuda:12.0-base nvidia-smi

# Si erreur, utiliser le mode CPU
docker compose -f docker-compose.cpu.yml up -d
```

### ProblÃ¨me : "Port 7860 dÃ©jÃ  utilisÃ©"

```bash
# Voir ce qui utilise le port
lsof -i :7860

# Changer le port dans docker-compose.yml
ports:
  - "7861:7860"
```

### ProblÃ¨me : "Erreur de build"

```bash
# Reconstruire sans cache
docker compose build --no-cache promptforge-web

# Supprimer les anciennes images
docker system prune -a
```

### ProblÃ¨me : "Lenteur extrÃªme (CPU)"

Si vous utilisez le mode CPU et que c'est trop lent :

1. Utiliser un modÃ¨le plus petit :
```bash
docker compose exec ollama ollama pull llama3.2:3b
```

2. Ou installer le support GPU (voir prÃ©requis)

---

## ğŸ“ Commandes Utiles

### Gestion des services

```bash
# DÃ©marrer tout
docker compose up -d

# ArrÃªter tout
docker compose down

# RedÃ©marrer
docker compose restart

# Voir les logs en temps rÃ©el
docker compose logs -f

# Voir les logs d'un service
docker compose logs -f promptforge-web
docker compose logs -f ollama
```

### Gestion Ollama

```bash
# Lister les modÃ¨les
docker compose exec ollama ollama list

# TÃ©lÃ©charger un modÃ¨le
docker compose exec ollama ollama pull <model>

# Supprimer un modÃ¨le
docker compose exec ollama ollama rm <model>

# Tester un modÃ¨le
docker compose exec ollama ollama run llama3.1 "Hello!"
```

### Maintenance

```bash
# Voir l'espace disque utilisÃ©
docker system df

# Nettoyer les ressources inutilisÃ©es
docker system prune

# Sauvegarder les donnÃ©es
tar -czvf promptforge-backup.tar.gz ./data

# Mettre Ã  jour Ollama
docker compose pull ollama
docker compose up -d ollama
```

### AccÃ©der au conteneur

```bash
# Shell dans le conteneur web
docker compose exec promptforge-web bash

# Shell dans Ollama
docker compose exec ollama bash
```

---

## ğŸŒ AccÃ¨s distant

Pour accÃ©der Ã  l'interface depuis un autre PC :

1. Trouver l'IP de votre machine :
```bash
ip addr show | grep inet
# ou sur Windows: ipconfig
```

2. AccÃ©der via : `http://<IP>:7860`

3. Si firewall, ouvrir le port :
```bash
# Ubuntu
sudo ufw allow 7860
```

---

## ğŸ“Š Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Docker Network                        â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                 â”‚     â”‚                             â”‚   â”‚
â”‚  â”‚     Ollama      â”‚â—„â”€â”€â”€â”€â”‚    PromptForge Web         â”‚   â”‚
â”‚  â”‚   (Port 11434)  â”‚     â”‚      (Port 7860)           â”‚   â”‚
â”‚  â”‚                 â”‚     â”‚                             â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚ llama3.1  â”‚  â”‚     â”‚  â”‚   Interface Gradio  â”‚   â”‚   â”‚
â”‚  â”‚  â”‚ mistral   â”‚  â”‚     â”‚  â”‚   + Recommandations â”‚   â”‚   â”‚
â”‚  â”‚  â”‚ qwen2.5   â”‚  â”‚     â”‚  â”‚   + Comparateur     â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â”‚                 â”‚     â”‚                             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚           â”‚                             â”‚                   â”‚
â”‚           â–¼                             â–¼                   â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚    â”‚ ollama-data  â”‚              â”‚   ./data/    â”‚          â”‚
â”‚    â”‚   (Volume)   â”‚              â”‚  (Bind mount)â”‚          â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Navigateur    â”‚
                    â”‚ localhost:7860  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ… Checklist de dÃ©ploiement

- [ ] Docker et Docker Compose installÃ©s
- [ ] Projet extrait dans un dossier
- [ ] `docker compose up -d` exÃ©cutÃ©
- [ ] Ollama en statut "healthy"
- [ ] ModÃ¨le tÃ©lÃ©chargÃ© (llama3.1)
- [ ] Interface accessible sur http://localhost:7860
- [ ] Test de reformatage rÃ©ussi

---

## ğŸ“ Support

En cas de problÃ¨me :

1. VÃ©rifier les logs : `docker compose logs`
2. Consulter la section [DÃ©pannage](#-dÃ©pannage)
3. RedÃ©marrer les services : `docker compose restart`

---

**Bon reformatage ! ğŸš€**
