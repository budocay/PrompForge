"""
Profils de reformatage optimisÃ©s pour diffÃ©rents modÃ¨les LLM.
Mis Ã  jour DÃ©cembre 2025 avec GPT-5.1, Gemini 3, Claude 4.5.
Inclut comparaison prix/performance.
"""

from dataclasses import dataclass
from enum import Enum
from typing import Optional


class TargetModel(Enum):
    """ModÃ¨le LLM cible pour le reformatage."""
    # Claude (Anthropic) - DÃ©cembre 2025
    CLAUDE_OPUS_4_5 = "claude-opus-4.5"
    CLAUDE_SONNET_4_5 = "claude-sonnet-4.5"
    CLAUDE_HAIKU_4_5 = "claude-haiku-4.5"
    
    # GPT (OpenAI) - DÃ©cembre 2025
    GPT_5_1 = "gpt-5.1"
    GPT_5_1_MINI = "gpt-5.1-mini"
    GPT_5_PRO = "gpt-5-pro"
    
    # Gemini (Google) - DÃ©cembre 2025
    GEMINI_3_PRO = "gemini-3-pro"
    GEMINI_3_FLASH = "gemini-3-flash"
    
    # Universel
    UNIVERSAL = "universal"


class PromptStyle(Enum):
    """Style de prompt souhaitÃ©."""
    CONCIS = "concis"
    DETAILLE = "detaille"
    TECHNIQUE = "technique"
    CREATIF = "creatif"


@dataclass
class ModelPricing:
    """Prix d'un modÃ¨le par million de tokens."""
    input_price: float      # $ par million tokens input
    output_price: float     # $ par million tokens output
    cached_input: float     # $ par million tokens (cache hit)
    context_window: int     # Taille max du contexte en tokens
    
    @property
    def avg_price_per_1k(self) -> float:
        """Prix moyen pour 1K tokens (ratio 1:1 input/output)."""
        return (self.input_price + self.output_price) / 2 / 1000
    
    def estimate_cost(self, input_tokens: int, output_tokens: int, cached_pct: float = 0) -> float:
        """Estime le coÃ»t d'une requÃªte."""
        cached_tokens = input_tokens * cached_pct
        fresh_tokens = input_tokens - cached_tokens
        input_cost = (fresh_tokens * self.input_price + cached_tokens * self.cached_input) / 1_000_000
        output_cost = output_tokens * self.output_price / 1_000_000
        return input_cost + output_cost


@dataclass
class ReformatProfile:
    """Profil de reformatage complet."""
    target_model: TargetModel
    style: PromptStyle
    include_examples: bool = False
    include_constraints: bool = True
    include_output_format: bool = True
    pricing: Optional[ModelPricing] = None


# ============================================
# Prix des modÃ¨les (DÃ©cembre 2025)
# ============================================

MODEL_PRICING = {
    # Claude (Anthropic)
    TargetModel.CLAUDE_OPUS_4_5: ModelPricing(
        input_price=5.0,
        output_price=25.0,
        cached_input=0.5,
        context_window=200_000
    ),
    TargetModel.CLAUDE_SONNET_4_5: ModelPricing(
        input_price=3.0,
        output_price=15.0,
        cached_input=0.3,
        context_window=1_000_000  # 1M tokens depuis aoÃ»t 2025
    ),
    TargetModel.CLAUDE_HAIKU_4_5: ModelPricing(
        input_price=0.25,
        output_price=1.25,
        cached_input=0.025,
        context_window=200_000
    ),
    
    # GPT (OpenAI)
    TargetModel.GPT_5_1: ModelPricing(
        input_price=1.25,
        output_price=10.0,
        cached_input=0.125,
        context_window=272_000
    ),
    TargetModel.GPT_5_1_MINI: ModelPricing(
        input_price=0.25,
        output_price=2.0,
        cached_input=0.025,
        context_window=200_000
    ),
    TargetModel.GPT_5_PRO: ModelPricing(
        input_price=5.0,
        output_price=20.0,
        cached_input=0.5,
        context_window=272_000
    ),
    
    # Gemini (Google)
    TargetModel.GEMINI_3_PRO: ModelPricing(
        input_price=2.0,
        output_price=12.0,
        cached_input=0.2,
        context_window=1_000_000
    ),
    TargetModel.GEMINI_3_FLASH: ModelPricing(
        input_price=0.5,
        output_price=2.0,
        cached_input=0.05,
        context_window=1_000_000
    ),
    
    # Universel (moyenne)
    TargetModel.UNIVERSAL: ModelPricing(
        input_price=1.0,
        output_price=5.0,
        cached_input=0.1,
        context_window=128_000
    ),
}


# ============================================
# System Prompts par ModÃ¨le
# BasÃ©s sur les documentations officielles:
# - Anthropic: docs.anthropic.com (XML tags)
# - OpenAI: platform.openai.com (Markdown + delimiters)
# - Google: ai.google.dev (XML-style tags ou Markdown)
# ============================================

# =============================================================================
# ğŸš¨ RÃˆGLE ANTI-BULLSHIT - AppliquÃ©e Ã  tous les prompts systÃ¨me
# =============================================================================

NO_BULLSHIT_RULE = """

ğŸš¨ RÃˆGLE CRITIQUE - AUCUNE MÃ‰TRIQUE INVENTÃ‰E ğŸš¨

Tu reformates des prompts, tu ne prÃ©dis PAS les performances. INTERDICTIONS ABSOLUES:

âŒ INTERDIT d'inventer des scores (pas de "SWE-bench: 92/100", "Code Quality: 98%")
âŒ INTERDIT d'inventer des temps (pas de "Temps: 15s â†’ 3s", "-80%")
âŒ INTERDIT d'inventer des pourcentages de gain (pas de "+48% clartÃ©")
âŒ INTERDIT de mentionner des benchmarks comme si tu les avais mesurÃ©s
âŒ INTERDIT d'inventer des IDs ou chemins de fichiers fictifs
âŒ INTERDIT de faire des tableaux "Avant/AprÃ¨s" avec des chiffres fictifs
âŒ INTERDIT d'ajouter des sections "Analyse", "MÃ©triques", "Gains", "Conclusion"

âœ… AUTORISÃ‰: Reformater le prompt avec une structure XML claire
âœ… AUTORISÃ‰: Ajouter du contexte, des instructions, des contraintes
âœ… AUTORISÃ‰: Proposer un format de sortie appropriÃ©

ğŸ¯ Ta rÃ©ponse = UNIQUEMENT le prompt XML reformatÃ©. RIEN D'AUTRE.
Pas d'analyse, pas de mÃ©triques, pas de tableaux, pas de conclusion."""

# =============================================================================

SYSTEM_PROMPT_CLAUDE_OPUS = """âš ï¸ FORMAT OBLIGATOIRE: XML UNIQUEMENT - PAS DE MARKDOWN âš ï¸

Tu transformes des demandes utilisateur en prompts XML optimisÃ©s pour Claude Opus 4.5.

âš ï¸ CONTEXTE IMPORTANT: Tu opÃ¨res dans un outil de DÃ‰VELOPPEMENT LOGICIEL (PromptForge).
Les demandes concernent TOUJOURS du code, de la programmation, des projets informatiques.
- "scanner" = analyser/parcourir du CODE SOURCE (PAS de l'OCR physique)
- "projet" = projet de DÃ‰VELOPPEMENT (repo git, fichiers code)
- "analyse" = analyse de CODE ou d'architecture logicielle

RÃˆGLE CRITIQUE: Ta rÃ©ponse DOIT Ãªtre UNIQUEMENT des balises XML.
âŒ INTERDIT: #, ##, **, -, *, ```, titres Markdown, listes avec tirets
âœ… OBLIGATOIRE: <balise>contenu</balise>

=== BALISES XML Ã€ UTILISER ===
<task_definition> - Objectif principal clair
<context> - Informations de contexte projet/technique
<requirements> - Liste des exigences fonctionnelles
<constraints> - Contraintes techniques/business
<output_format> - Format de sortie attendu
<thinking_approach> - Approche de raisonnement (optionnel, pour tÃ¢ches complexes)

=== EXEMPLE CORRECT ===

Demande: "refonte UI backoffice"

<task_definition>
CrÃ©er un thÃ¨me global unifiÃ© pour le backoffice qui harmonise l'UI et les couleurs.
</task_definition>

<context>
Projet: Application backoffice existante
ProblÃ¨me: IncohÃ©rence visuelle entre les pages, plusieurs jeux de couleurs
Stack: Tailwind CSS, TypeScript
</context>

<requirements>
ThÃ¨me global applicable Ã  toutes les pages
Fonction getSectionColor() pour cohÃ©rence des couleurs
Support dark mode avec classes dark:*
ReprÃ©sentation UI/UX unique par typologie mais cohÃ©rente globalement
</requirements>

<constraints>
Respecter les conventions de code existantes
Maintenir la lisibilitÃ© du code
CompatibilitÃ© avec le systÃ¨me de design actuel
</constraints>

<output_format>
Configuration theme.config.ts mise Ã  jour
Fonction getSectionColor() implÃ©mentÃ©e
Classes Tailwind pour dark mode
Documentation des changements
</output_format>

=== FIN EXEMPLE ===

âš ï¸ RAPPEL FINAL:
- JAMAIS de Markdown (pas de #, ##, **, -, listes)
- UNIQUEMENT des balises XML <...>...</...>
- Commence DIRECTEMENT par <task_definition>
- MÃªme langue que l'utilisateur
- DÃ©taille chaque section (Opus excelle sur les tÃ¢ches complexes)
- TOUJOURS interprÃ©ter dans le contexte du DÃ‰VELOPPEMENT LOGICIEL"""


SYSTEM_PROMPT_CLAUDE_SONNET = """âš ï¸ FORMAT OBLIGATOIRE: XML UNIQUEMENT - PAS DE MARKDOWN âš ï¸

Tu transformes des demandes en prompts XML optimisÃ©s pour Claude Sonnet 4.5.

âš ï¸ CONTEXTE: Outil de DÃ‰VELOPPEMENT LOGICIEL. Les demandes concernent du CODE/programmation.
- "scanner" = analyser du CODE SOURCE (pas OCR)
- "projet" = projet de dÃ©veloppement (git, fichiers code)

RÃˆGLE CRITIQUE: Ta rÃ©ponse DOIT Ãªtre UNIQUEMENT des balises XML.
âŒ INTERDIT: #, ##, **, -, *, ```, titres Markdown, listes avec tirets
âœ… OBLIGATOIRE: <balise>contenu</balise>

=== BALISES XML Ã€ UTILISER ===
<task> - Objectif principal
<context> - Contexte technique/projet
<instructions> - Ã‰tapes numÃ©rotÃ©es (1. 2. 3. dans le contenu XML)
<output_format> - Format de sortie attendu

=== EXEMPLE CORRECT ===

Demande: "corrige mon code"

<task>
Analyser et corriger le code fourni en identifiant bugs et amÃ©liorations possibles.
</task>

<context>
Code existant nÃ©cessitant debug et optimisation.
Langage et framework Ã  dÃ©tecter depuis le code fourni.
</context>

<instructions>
1. Identifier les bugs et erreurs de logique
2. Corriger les problÃ¨mes de syntaxe
3. AmÃ©liorer la lisibilitÃ© et les performances
4. SuggÃ©rer des refactorisations si pertinent
</instructions>

<output_format>
Code corrigÃ© avec commentaires sur les changements
Liste des bugs identifiÃ©s et corrigÃ©s
Suggestions d'amÃ©lioration optionnelles
</output_format>

=== FIN EXEMPLE ===

âš ï¸ RAPPEL: JAMAIS de Markdown (#, ##, **, -). Commence DIRECTEMENT par <task>. MÃªme langue."""


SYSTEM_PROMPT_CLAUDE_HAIKU = """âš ï¸ XML UNIQUEMENT - PAS DE MARKDOWN âš ï¸

Contexte: Outil de DÃ‰VELOPPEMENT LOGICIEL. Demandes = CODE/programmation.

RÃ©Ã©cris en XML court et efficace pour Claude Haiku 4.5.

âŒ INTERDIT: #, ##, **, -, listes Markdown
âœ… OBLIGATOIRE: <balise>contenu</balise>

=== EXEMPLE ===
Demande: "explique les promises"

<context>
Question JavaScript sur les Promises et programmation asynchrone.
</context>

<instructions>
Expliquer les Promises: concept, syntaxe async/await, exemples pratiques.
</instructions>

<output_format>
Explication concise avec exemples de code fonctionnels.
</output_format>

=== FIN ===

âš ï¸ RÃˆGLE: XML seulement, commence par <context>, mÃªme langue."""


SYSTEM_PROMPT_GPT_5_1 = """Tu rÃ©Ã©cris des demandes en prompts Markdown optimisÃ©s pour GPT-5.1.

âš ï¸ CONTEXTE: Outil de DÃ‰VELOPPEMENT LOGICIEL. Les demandes concernent du CODE/programmation.
- "scanner" = analyser du CODE SOURCE (pas OCR physique)
- "projet" = projet de dÃ©veloppement (git, fichiers code)

=== FORCES DE GPT-5.1 ===
- ExtrÃªmement steerable (suit les instructions avec prÃ©cision)
- 45% moins d'hallucinations que GPT-4
- Contexte 272K tokens

=== RÃˆGLES GPT-5.1 ===
- Instructions EXPLICITES et NON AMBIGUÃ‹S
- Ã‰viter les contradictions
- Format de sortie PRÃ‰CIS

=== EXEMPLE ===
Demande: "crÃ©Ã© un dashboard"

Ta rÃ©ponse:
## Contexte
Application web nÃ©cessitant un tableau de bord d'administration pour visualiser les mÃ©triques.

## Objectif
CrÃ©er un dashboard responsive avec KPIs, graphiques interactifs et liste d'activitÃ©s.

## Exigences
- Cartes KPIs avec statistiques clÃ©s
- Graphiques interactifs (line/bar charts)
- Liste des activitÃ©s rÃ©centes paginÃ©e
- Design responsive mobile-first
- Composants rÃ©utilisables

## Contraintes
- Performance: lazy loading des donnÃ©es
- AccessibilitÃ© WCAG 2.1 niveau AA

## Format de sortie attendu
Composants React avec:
1. Structure des fichiers
2. Code commentÃ©
3. Styles Tailwind
=== FIN ===

RÃˆGLES ABSOLUES:
- RÃ©ponds UNIQUEMENT avec le Markdown structurÃ©
- PAS d'intro "Voici le prompt..."
- PAS d'explication aprÃ¨s
- Sections: Contexte, Objectif, Exigences, Contraintes, Format de sortie
- MÃŠME LANGUE que l'utilisateur"""


SYSTEM_PROMPT_GPT_5_1_MINI = """Contexte: Outil de DÃ‰VELOPPEMENT LOGICIEL (code/programmation).
Tu rÃ©Ã©cris en prompts Markdown courts pour GPT-5.1 Mini.

=== EXEMPLE ===
Demande: "trie une liste"

Ta rÃ©ponse:
## Objectif
Trier une liste en Python avec les mÃ©thodes natives.

## Exigences
- Montrer sorted() pour copie triÃ©e
- Montrer .sort() pour tri in-place
- Exemples avec listes de nombres et strings

## Format de sortie
Code Python commentÃ©, concis.
=== FIN ===

RÃˆGLES: Markdown court. Pas d'intro. MÃªme langue."""


SYSTEM_PROMPT_GPT_5_PRO = """Tu rÃ©Ã©cris des demandes complexes en prompts Markdown dÃ©taillÃ©s pour GPT-5 Pro.

âš ï¸ CONTEXTE: Outil de DÃ‰VELOPPEMENT LOGICIEL. Les demandes concernent du CODE/programmation.
- "scanner" = analyser du CODE SOURCE (pas OCR)
- "projet" = projet de dÃ©veloppement (git, fichiers)

=== FORCES DE GPT-5 PRO ===
- Raisonnement trÃ¨s approfondi (jusqu'Ã  10+ minutes)
- IdÃ©al: sciences, maths, recherche, problÃ¨mes complexes

=== ASTUCE ===
Ajouter "RÃ©flÃ©chis en profondeur Ã  ce problÃ¨me" dÃ©clenche le mode raisonnement.

=== EXEMPLE ===
Demande: "optimise ma requÃªte SQL lente"

Ta rÃ©ponse:
## DÃ©finition du problÃ¨me
RequÃªte SQL avec problÃ¨mes de performance sÃ©vÃ¨res nÃ©cessitant une analyse approfondie et systÃ©matique.

## Contexte
- Base de donnÃ©es relationnelle (PostgreSQL/MySQL)
- Tables volumineuses avec jointures multiples potentielles
- Temps d'exÃ©cution actuel inacceptable pour la production

## Analyse requise
RÃ©flÃ©chis en profondeur Ã  ce problÃ¨me:
1. Analyser le plan d'exÃ©cution (EXPLAIN ANALYZE)
2. Identifier les goulots d'Ã©tranglement (full table scans, nested loops inefficaces)
3. Ã‰valuer la cardinalitÃ© des jointures
4. VÃ©rifier les index existants vs manquants
5. ConsidÃ©rer la dÃ©normalisation si bÃ©nÃ©fique

## Contraintes
- Ne pas casser la logique mÃ©tier existante
- Maintenir la compatibilitÃ© avec l'ORM si utilisÃ©

## Format de sortie attendu
1. Diagnostic dÃ©taillÃ© avec mÃ©triques avant/aprÃ¨s
2. RequÃªte optimisÃ©e avec justifications ligne par ligne
3. Scripts CREATE INDEX recommandÃ©s
4. Estimation du gain de performance attendu
=== FIN ===

RÃˆGLES:
- Markdown dÃ©taillÃ© pour problÃ¨mes complexes
- Inclure "RÃ©flÃ©chis en profondeur" pour deep reasoning
- Pas d'intro, pas d'explication aprÃ¨s
- MÃªme langue"""


SYSTEM_PROMPT_GEMINI_3_PRO = """âš ï¸ FORMAT OBLIGATOIRE: XML UNIQUEMENT - PAS DE MARKDOWN âš ï¸

Tu transformes des demandes en prompts XML optimisÃ©s pour Gemini 3 Pro.

âš ï¸ CONTEXTE: Outil de DÃ‰VELOPPEMENT LOGICIEL. Les demandes concernent du CODE/programmation.
- "scanner" = analyser du CODE SOURCE (pas OCR physique)
- "projet" = projet de dÃ©veloppement (git, fichiers code)

RÃˆGLE CRITIQUE: Ta rÃ©ponse DOIT Ãªtre UNIQUEMENT des balises XML.
âŒ INTERDIT: #, ##, **, -, *, ```, Markdown
âœ… OBLIGATOIRE: <balise>contenu</balise>

=== BALISES XML Ã€ UTILISER ===
<objective> - Objectif principal
<context> - Contexte (Gemini excelle sur documents longs)
<analysis_tasks> - TÃ¢ches d'analyse
<output_format> - Format de sortie

=== EXEMPLE CORRECT ===

Demande: "analyse ce document"

<objective>
Analyser le document fourni pour extraire les informations clÃ©s et produire une synthÃ¨se actionnable.
</objective>

<context>
Document Ã  analyser en profondeur.
Gemini 3 Pro peut traiter des documents trÃ¨s longs (jusqu'Ã  750K mots).
Utiliser le contexte Ã©tendu pour une analyse complÃ¨te.
</context>

<analysis_tasks>
1. Identifier les thÃ¨mes principaux et secondaires
2. Extraire les donnÃ©es chiffrÃ©es et faits importants
3. RepÃ©rer les arguments clÃ©s et conclusions
4. DÃ©tecter les incohÃ©rences ou points d'attention
</analysis_tasks>

<output_format>
RÃ©sumÃ© exÃ©cutif (5-10 lignes)
Points clÃ©s numÃ©rotÃ©s
DonnÃ©es/chiffres importants
Recommandations ou points d'action
</output_format>

=== FIN ===

âš ï¸ RAPPEL: JAMAIS de Markdown. Commence par <objective>. MÃªme langue."""


SYSTEM_PROMPT_GEMINI_3_FLASH = """âš ï¸ XML UNIQUEMENT - PAS DE MARKDOWN âš ï¸

Contexte: Outil de DÃ‰VELOPPEMENT LOGICIEL. Demandes = CODE/programmation.

RÃ©Ã©cris en XML court et efficace pour Gemini 3 Flash.

âŒ INTERDIT: #, ##, **, -, Markdown
âœ… OBLIGATOIRE: <balise>contenu</balise>

=== EXEMPLE ===
Demande: "traduis en anglais"

<context>
Traduction franÃ§ais vers anglais demandÃ©e.
</context>

<task>
Traduire le texte en prÃ©servant le sens, le ton et les nuances.
</task>

<output_format>
Texte traduit en anglais, fidÃ¨le Ã  l'original.
</output_format>

=== FIN ===

âš ï¸ RÃˆGLE: XML seulement, commence par <context>, mÃªme langue."""


SYSTEM_PROMPT_UNIVERSAL = """âš ï¸ FORMAT OBLIGATOIRE: XML UNIQUEMENT - PAS DE MARKDOWN âš ï¸

Tu transformes des demandes utilisateur en prompts XML structurÃ©s.

âš ï¸ CONTEXTE IMPORTANT: Tu opÃ¨res dans un outil de DÃ‰VELOPPEMENT LOGICIEL (PromptForge).
Les demandes concernent TOUJOURS du code, de la programmation, des projets informatiques.
- "scanner" = analyser/parcourir du CODE SOURCE (PAS de l'OCR physique)
- "projet" = projet de DÃ‰VELOPPEMENT (repo git, fichiers code)
- "analyse" = analyse de CODE ou d'architecture logicielle

RÃˆGLE CRITIQUE: Ta rÃ©ponse DOIT Ãªtre UNIQUEMENT des balises XML.
âŒ INTERDIT: #, ##, ###, **, *, -, ```, titres Markdown, listes avec tirets/astÃ©risques
âœ… OBLIGATOIRE: <balise>contenu</balise>

=== BALISES XML Ã€ UTILISER ===
<context> - Contexte du projet/de la demande
<instructions> - Ce que le modÃ¨le doit faire (liste numÃ©rotÃ©e OK Ã  l'intÃ©rieur)
<output_format> - Format de sortie attendu
<constraints> - Contraintes optionnelles

=== EXEMPLE CORRECT ===

Demande: "aide moi avec mon projet flutter"

<context>
Projet Flutter nÃ©cessitant assistance technique.
Type: Application mobile cross-platform.
</context>

<instructions>
1. Analyser les besoins spÃ©cifiques du projet
2. Proposer des solutions adaptÃ©es Ã  Flutter
3. Fournir du code Dart fonctionnel
4. Respecter les bonnes pratiques Flutter/Dart
</instructions>

<output_format>
RÃ©ponse structurÃ©e avec:
Code Dart commentÃ©
Explications des choix techniques
Suggestions d'amÃ©lioration
</output_format>

=== FIN EXEMPLE ===

âš ï¸ RAPPEL FINAL:
- JAMAIS de Markdown (pas de #, ##, **, -, *)
- UNIQUEMENT des balises XML <...>...</...>
- Commence DIRECTEMENT par <context>
- Utilise la MÃŠME LANGUE que l'utilisateur
- Pas de texte avant ou aprÃ¨s le XML"""


# ============================================
# Modificateurs de style
# ============================================

STYLE_MODIFIERS = {
    PromptStyle.CONCIS: """
## Style: CONCIS
- RÃ©ponses directes et courtes
- Pas de dÃ©tails superflus
- Focus sur l'essentiel""",
    
    PromptStyle.DETAILLE: """
## Style: DÃ‰TAILLÃ‰
- Explications complÃ¨tes
- Couvre tous les aspects
- Inclut le raisonnement""",
    
    PromptStyle.TECHNIQUE: """
## Style: TECHNIQUE
- Terminologie prÃ©cise
- DÃ©tails d'implÃ©mentation
- Best practices incluses""",
    
    PromptStyle.CREATIF: """
## Style: CRÃ‰ATIF
- Place Ã  l'interprÃ©tation
- Encourage l'originalitÃ©
- Focus sur l'intention"""
}


# ============================================
# Fonctions utilitaires
# ============================================

SYSTEM_PROMPTS = {
    TargetModel.CLAUDE_OPUS_4_5: SYSTEM_PROMPT_CLAUDE_OPUS,
    TargetModel.CLAUDE_SONNET_4_5: SYSTEM_PROMPT_CLAUDE_SONNET,
    TargetModel.CLAUDE_HAIKU_4_5: SYSTEM_PROMPT_CLAUDE_HAIKU,
    TargetModel.GPT_5_1: SYSTEM_PROMPT_GPT_5_1,
    TargetModel.GPT_5_1_MINI: SYSTEM_PROMPT_GPT_5_1_MINI,
    TargetModel.GPT_5_PRO: SYSTEM_PROMPT_GPT_5_PRO,
    TargetModel.GEMINI_3_PRO: SYSTEM_PROMPT_GEMINI_3_PRO,
    TargetModel.GEMINI_3_FLASH: SYSTEM_PROMPT_GEMINI_3_FLASH,
    TargetModel.UNIVERSAL: SYSTEM_PROMPT_UNIVERSAL,
}


def get_system_prompt(target: TargetModel) -> str:
    """Retourne le system prompt pour le modÃ¨le cible avec rÃ¨gle anti-bullshit."""
    base_prompt = SYSTEM_PROMPTS.get(target, SYSTEM_PROMPT_UNIVERSAL)
    # Ajouter la rÃ¨gle anti-bullshit Ã  TOUS les prompts
    return base_prompt + NO_BULLSHIT_RULE


def get_style_modifier(style: PromptStyle) -> str:
    """Retourne le modificateur de style."""
    return STYLE_MODIFIERS.get(style, "")


def build_reformat_prompt(
    raw_prompt: str,
    project_context: str,
    profile: ReformatProfile
) -> tuple[str, str]:
    """Construit le prompt pour le reformatage - version simplifiÃ©e."""
    system_prompt = get_system_prompt(profile.target_model)
    style_modifier = get_style_modifier(profile.style)
    if style_modifier:
        system_prompt += "\n" + style_modifier
    
    # User prompt SIMPLE et DIRECT
    if project_context.strip():
        user_prompt = f"""CONTEXTE PROJET:
{project_context}

DEMANDE Ã€ REFORMATER:
{raw_prompt}

RÃ©Ã©cris cette demande en prompt structurÃ©. IntÃ¨gre les infos du contexte projet."""
    else:
        user_prompt = f"""DEMANDE Ã€ REFORMATER:
{raw_prompt}

RÃ©Ã©cris cette demande en prompt structurÃ©."""
    
    return system_prompt, user_prompt


def get_model_optimization_tips(target: TargetModel) -> str:
    """Retourne des conseils d'optimisation spÃ©cifiques au modÃ¨le cible."""
    tips = {
        TargetModel.CLAUDE_OPUS_4_5: """
Forces Ã  exploiter:
- Excelle sur les tÃ¢ches complexes et longues (agents, architecture, code avancÃ©)
- Comprend trÃ¨s bien les balises XML structurÃ©es
- GÃ¨re des contextes trÃ¨s longs (200K tokens)
- Peut utiliser le mode "thinking" pour rÃ©flexion approfondie

Optimisations:
â†’ Inclure un contexte COMPLET et dÃ©taillÃ©
â†’ Ajouter une section <thinking_approach> pour tÃ¢ches complexes
â†’ Utiliser <quality_criteria> pour l'auto-Ã©valuation
â†’ ÃŠtre explicite sur les nuances et cas particuliers""",

        TargetModel.CLAUDE_SONNET_4_5: """
Forces Ã  exploiter:
- Excellent Ã©quilibre performance/coÃ»t
- TrÃ¨s bon pour le code et les agents au quotidien
- Mode hybride: rapide OU raisonnement Ã©tendu

Optimisations:
â†’ Contexte essentiel mais concis
â†’ Instructions claires et directes
â†’ Bien structurer avec <requirements> et <constraints>""",

        TargetModel.CLAUDE_HAIKU_4_5: """
Forces Ã  exploiter:
- Ultra-rapide et Ã©conomique
- IdÃ©al pour tÃ¢ches simples et volume Ã©levÃ©

Optimisations:
â†’ Prompt TRÃˆS COURT (moins c'est mieux)
â†’ Seulement 2-3 sections XML essentielles
â†’ Instructions directes, pas de fioritures""",

        TargetModel.GPT_5_1: """
Forces Ã  exploiter:
- ExtrÃªmement steerable (suit les instructions avec prÃ©cision chirurgicale)
- 45% moins d'hallucinations que GPT-4
- Contexte 272K tokens

Optimisations:
â†’ Instructions EXPLICITES et non ambiguÃ«s
â†’ Ã‰viter les contradictions dans les instructions
â†’ Format de sortie PRÃ‰CIS (GPT-5.1 le suivra exactement)
â†’ Sections claires: Contexte, Objectif, Exigences, Contraintes""",

        TargetModel.GPT_5_1_MINI: """
Forces Ã  exploiter:
- Rapide et trÃ¨s Ã©conomique
- Steerable comme GPT-5.1
- Bon pour tÃ¢ches simples Ã  moyennes

Optimisations:
â†’ Prompt CONCIS
â†’ Instructions directes
â†’ Ã‰viter le sur-prompting""",

        TargetModel.GPT_5_PRO: """
Forces Ã  exploiter:
- Raisonnement trÃ¨s approfondi (jusqu'Ã  10+ min de rÃ©flexion)
- IdÃ©al: sciences, maths, recherche, problÃ¨mes complexes

Optimisations:
â†’ Ajouter "RÃ©flÃ©chis en profondeur Ã  ce problÃ¨me" pour deep reasoning
â†’ Section "DÃ©finition du problÃ¨me" trÃ¨s dÃ©taillÃ©e
â†’ HypothÃ¨ses et contraintes explicites
â†’ Contexte technique complet""",

        TargetModel.GEMINI_3_PRO: """
Forces Ã  exploiter:
- Contexte Ã‰NORME de 1M tokens
- Excellent pour documents trÃ¨s longs
- Multimodal avancÃ© (texte, image, audio, vidÃ©o)

Optimisations:
â†’ Inclure TOUT le contexte pertinent (il gÃ¨re)
â†’ Section <objective> pour l'objectif principal
â†’ IdÃ©al pour analyse de documents entiers""",

        TargetModel.GEMINI_3_FLASH: """
Forces Ã  exploiter:
- TrÃ¨s rapide comme Haiku
- Contexte 1M tokens comme Pro

Optimisations:
â†’ Prompt court mais contexte peut Ãªtre long
â†’ Instructions directes""",

        TargetModel.UNIVERSAL: """
CompatibilitÃ© maximale avec tous les LLMs:
- Structure XML claire et standard
- Instructions explicites et non ambiguÃ«s
- Niveau de dÃ©tail modÃ©rÃ©
- Format de sortie bien dÃ©fini"""
    }
    
    return tips.get(target, tips[TargetModel.UNIVERSAL])


# ============================================
# Profils prÃ©dÃ©finis
# ============================================

PRESET_PROFILES = {
    # Claude (Anthropic)
    "claude_opus_4.5": ReformatProfile(
        target_model=TargetModel.CLAUDE_OPUS_4_5,
        style=PromptStyle.DETAILLE,
        include_examples=True,
        pricing=MODEL_PRICING[TargetModel.CLAUDE_OPUS_4_5]
    ),
    "claude_sonnet_4.5": ReformatProfile(
        target_model=TargetModel.CLAUDE_SONNET_4_5,
        style=PromptStyle.TECHNIQUE,
        include_examples=True,
        pricing=MODEL_PRICING[TargetModel.CLAUDE_SONNET_4_5]
    ),
    "claude_haiku_4.5": ReformatProfile(
        target_model=TargetModel.CLAUDE_HAIKU_4_5,
        style=PromptStyle.CONCIS,
        include_examples=False,
        pricing=MODEL_PRICING[TargetModel.CLAUDE_HAIKU_4_5]
    ),
    
    # GPT (OpenAI)
    "gpt_5.1": ReformatProfile(
        target_model=TargetModel.GPT_5_1,
        style=PromptStyle.DETAILLE,
        include_examples=True,
        pricing=MODEL_PRICING[TargetModel.GPT_5_1]
    ),
    "gpt_5.1_mini": ReformatProfile(
        target_model=TargetModel.GPT_5_1_MINI,
        style=PromptStyle.CONCIS,
        include_examples=False,
        pricing=MODEL_PRICING[TargetModel.GPT_5_1_MINI]
    ),
    "gpt_5_pro": ReformatProfile(
        target_model=TargetModel.GPT_5_PRO,
        style=PromptStyle.DETAILLE,
        include_examples=True,
        pricing=MODEL_PRICING[TargetModel.GPT_5_PRO]
    ),
    
    # Gemini (Google)
    "gemini_3_pro": ReformatProfile(
        target_model=TargetModel.GEMINI_3_PRO,
        style=PromptStyle.DETAILLE,
        include_examples=True,
        pricing=MODEL_PRICING[TargetModel.GEMINI_3_PRO]
    ),
    "gemini_3_flash": ReformatProfile(
        target_model=TargetModel.GEMINI_3_FLASH,
        style=PromptStyle.CONCIS,
        include_examples=False,
        pricing=MODEL_PRICING[TargetModel.GEMINI_3_FLASH]
    ),
    
    # Universel
    "universel": ReformatProfile(
        target_model=TargetModel.UNIVERSAL,
        style=PromptStyle.DETAILLE,
        include_examples=True,
        pricing=MODEL_PRICING[TargetModel.UNIVERSAL]
    ),
}


def get_profile(name: str) -> ReformatProfile:
    """RÃ©cupÃ¨re un profil prÃ©dÃ©fini."""
    return PRESET_PROFILES.get(name, PRESET_PROFILES["universel"])


def list_profiles() -> list[str]:
    """Liste les noms des profils disponibles."""
    return list(PRESET_PROFILES.keys())


def get_pricing(model: TargetModel) -> ModelPricing:
    """RÃ©cupÃ¨re le pricing d'un modÃ¨le."""
    return MODEL_PRICING.get(model, MODEL_PRICING[TargetModel.UNIVERSAL])


# ============================================
# Comparaison des modÃ¨les
# ============================================

def compare_models(input_tokens: int = 1000, output_tokens: int = 500) -> list[dict]:
    """
    Compare les modÃ¨les par prix et caractÃ©ristiques.
    
    Args:
        input_tokens: Nombre de tokens en entrÃ©e pour le calcul
        output_tokens: Nombre de tokens en sortie pour le calcul
    
    Returns:
        Liste triÃ©e par coÃ»t (moins cher en premier)
    """
    comparisons = []
    
    for model, pricing in MODEL_PRICING.items():
        cost = pricing.estimate_cost(input_tokens, output_tokens)
        comparisons.append({
            "model": model.value,
            "cost": cost,
            "cost_display": f"${cost:.4f}",
            "input_price": f"${pricing.input_price}/M",
            "output_price": f"${pricing.output_price}/M",
            "context": f"{pricing.context_window // 1000}K",
            "tier": _get_model_tier(model),
        })
    
    return sorted(comparisons, key=lambda x: x["cost"])


def _get_model_tier(model: TargetModel) -> str:
    """Retourne le tier de performance du modÃ¨le."""
    premium = [TargetModel.CLAUDE_OPUS_4_5, TargetModel.GPT_5_PRO, TargetModel.GPT_5_1]
    mid = [TargetModel.CLAUDE_SONNET_4_5, TargetModel.GEMINI_3_PRO]
    
    if model in premium:
        return "ğŸ”¥ Premium"
    elif model in mid:
        return "âš¡ Performant"
    else:
        return "ğŸ’° Ã‰conomique"


def get_recommendation(task_type: str) -> dict:
    """
    Recommande un modÃ¨le selon le type de tÃ¢che.
    
    Args:
        task_type: "code", "chat", "analysis", "creative", "budget"
    
    Returns:
        Dictionnaire avec recommandation et alternatives
    """
    recommendations = {
        "code": {
            "best": "claude_opus_4.5",
            "balanced": "claude_sonnet_4.5",
            "budget": "gpt_5.1_mini",
            "reason": "Opus 4.5 excelle en code complexe, Sonnet pour le quotidien"
        },
        "chat": {
            "best": "gpt_5.1",
            "balanced": "gemini_3_flash",
            "budget": "claude_haiku_4.5",
            "reason": "GPT-5.1 est plus naturel, Flash/Haiku pour le volume"
        },
        "analysis": {
            "best": "gemini_3_pro",
            "balanced": "claude_sonnet_4.5",
            "budget": "gpt_5.1_mini",
            "reason": "Gemini 3 Pro avec 1M tokens pour les gros documents"
        },
        "creative": {
            "best": "gpt_5.1",
            "balanced": "claude_sonnet_4.5",
            "budget": "gemini_3_flash",
            "reason": "GPT-5.1 moins sycophantique, plus crÃ©atif"
        },
        "budget": {
            "best": "gpt_5.1_mini",
            "balanced": "claude_haiku_4.5",
            "budget": "gemini_3_flash",
            "reason": "GPT-5.1 Mini offre le meilleur rapport qualitÃ©/prix"
        },
    }
    
    return recommendations.get(task_type, recommendations["budget"])


def format_comparison_table() -> str:
    """GÃ©nÃ¨re un tableau de comparaison formatÃ©."""
    comparisons = compare_models()
    
    lines = [
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”",
        "â”‚ ModÃ¨le               â”‚ Input/M       â”‚ Output/M      â”‚ Contexte â”‚ Tier        â”‚",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤",
    ]
    
    for c in comparisons:
        model = c["model"][:20].ljust(20)
        input_p = c["input_price"].ljust(13)
        output_p = c["output_price"].ljust(13)
        context = c["context"].ljust(8)
        tier = c["tier"].ljust(11)
        lines.append(f"â”‚ {model} â”‚ {input_p} â”‚ {output_p} â”‚ {context} â”‚ {tier} â”‚")
    
    lines.append("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    
    return "\n".join(lines)
