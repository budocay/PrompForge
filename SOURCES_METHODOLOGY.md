# üìä PromptForge - Sources des Benchmarks & M√©thodologie

Ce document d√©taille les sources utilis√©es pour les recommandations de mod√®les et explique la m√©thodologie de calcul des scores.

---

## üìö Sources Officielles

### Anthropic (Claude)

| Source | URL | Date |
|--------|-----|------|
| Claude Opus 4.5 Announcement | https://www.anthropic.com/news/claude-opus-4-5 | Nov 2025 |
| Claude Opus 4.5 Model Card | https://www.anthropic.com/claude/opus | Nov 2025 |

**Benchmarks cl√©s:**
- **SWE-bench Verified:** 80.9% (leader industrie)
- **Terminal-Bench 2.0:** 59.3%
- **OSWorld (computer use):** 66.3%
- **Safety:** ASL-3 (Advanced Safety Level 3)

---

### OpenAI (GPT-5)

| Source | URL | Date |
|--------|-----|------|
| Introducing GPT-5 | https://openai.com/index/introducing-gpt-5/ | Ao√ªt 2025 |
| HealthBench Paper | https://arxiv.org/abs/2505.08775 | Mai 2025 |
| HealthBench Announcement | https://openai.com/index/healthbench/ | Mai 2025 |

**Benchmarks cl√©s:**
- **HealthBench Hard:** 46.2% (SOTA m√©dical)
- **Hallucinations:** -45% vs GPT-4
- **AIME 2025:** 94.6% (sans tools)
- **GPQA Diamond:** 88.4%

**HealthBench - M√©thodologie:**
- 5,000 conversations m√©dicales r√©alistes
- 262 m√©decins de 60 pays
- 48,562 crit√®res d'√©valuation uniques

---

### Google (Gemini 3)

| Source | URL | Date |
|--------|-----|------|
| Gemini 3 Announcement | https://blog.google/products/gemini/gemini-3/ | Nov 2025 |
| Gemini 3 Pro Model Card | https://deepmind.google/models/gemini/pro/ | Nov 2025 |

**Benchmarks cl√©s:**
- **GPQA Diamond:** 91.9% (leader PhD-level)
- **AIME 2025:** 95-100%
- **MathArena Apex:** 23.4% (leader)
- **Contexte:** 1M tokens
- **LMArena Leaderboard:** 1501 Elo

---

## üèÜ Benchmarks de R√©f√©rence

### SWE-bench Verified (Code)

**Description:** √âvalue la capacit√© √† r√©soudre de vrais bugs provenant de repositories GitHub populaires.

**Source:** https://www.swebench.com/

**Scores (Novembre 2025):**

| Mod√®le | Score |
|--------|-------|
| Claude Opus 4.5 | **80.9%** üëë |
| GPT-5.1 Codex Max | 77.9% |
| Claude Sonnet 4.5 | 77.2% |
| GPT-5.1 | 76.3% |
| Gemini 3 Pro | 76.2% |

**Pourquoi c'est pertinent:** Ce benchmark mesure la capacit√© r√©elle √† corriger du code dans des contextes professionnels, pas juste √† g√©n√©rer du code isol√©.

---

### GPQA Diamond (Recherche/Science)

**Description:** Questions de niveau doctorat en physique, chimie et biologie.

**Source:** https://arxiv.org/abs/2311.12022

**Scores (Novembre 2025):**

| Mod√®le | Score |
|--------|-------|
| Gemini 3 Pro | **91.9%** üëë |
| GPT-5.1 | 88.1% |
| Claude Sonnet 4.5 | 83.4% |

**Pourquoi c'est pertinent:** Mesure la compr√©hension scientifique profonde n√©cessaire pour la recherche avanc√©e.

---

### HealthBench Hard (M√©dical)

**Description:** √âvaluation m√©dicale rigoureuse bas√©e sur 5,000 conversations r√©alistes, √©valu√©es par 262 m√©decins de 60 pays.

**Source:** https://arxiv.org/abs/2505.08775

**Scores (Ao√ªt 2025):**

| Mod√®le | Score |
|--------|-------|
| GPT-5 | **46.2%** üëë |
| o3 | 31.6% |
| GPT-4o | 32.0% |

**Pourquoi c'est pertinent:** Premier benchmark m√©dical vraiment rigoureux avec validation par des professionnels de sant√©.

---

### AIME 2025 (Math√©matiques)

**Description:** American Invitational Mathematics Examination - comp√©tition math√©matique de niveau lyc√©e avanc√©.

**Source:** https://artofproblemsolving.com/wiki/index.php/AIME

**Scores (Novembre 2025):**

| Mod√®le | Score (sans tools) | Score (avec tools) |
|--------|-------------------|-------------------|
| GPT-5 Pro | - | **100%** üëë |
| Gemini 3 Pro | 95% | 100% |
| GPT-5.1 | 94.6% | - |
| Claude Sonnet 4.5 | 87% | - |

---

## üìê M√©thodologie de Calcul

### Score de Pertinence (0-100%)

Le score de pertinence par domaine est calcul√© ainsi:

```
Score = (Benchmark_Score √ó 0.7) + (Retours_Usage √ó 0.3)
```

**Composants:**
1. **Benchmark Score (70%):** R√©sultats officiels sur les benchmarks de r√©f√©rence
2. **Retours Usage (30%):** Feedback de la communaut√© et tests pratiques

### Estimation des Tokens

```python
# Tokens estim√©s selon le type de t√¢che
TOKEN_ESTIMATES = {
    'code': (800, 1500),      # (input, output)
    'legal': (1200, 2000),
    'medical': (600, 1000),
    'creative': (400, 1200),
    'research': (1000, 2500),
    'general': (500, 800),
}
```

### Co√ªt Estim√©

```
Co√ªt = (input_tokens √ó prix_input / 1M) + (output_tokens √ó prix_output / 1M)
```

**Prix API (D√©cembre 2025):**

| Mod√®le | Input ($/1M) | Output ($/1M) |
|--------|-------------|---------------|
| Claude Opus 4.5 | $5.00 | $25.00 |
| Claude Sonnet 4.5 | $3.00 | $15.00 |
| Claude Haiku 4.5 | $0.25 | $1.25 |
| GPT-5.1 | $1.25 | $10.00 |
| GPT-5.1 Mini | $0.25 | $2.00 |
| GPT-5 Pro | $5.00 | $20.00 |
| Gemini 3 Pro | $2.00 | $12.00 |
| Gemini 3 Flash | $0.50 | $2.00 |

### Score de Valeur

```
Valeur = Score_Pertinence / (Co√ªt √ó 100 + 0.001)
```

Plus la valeur est √©lev√©e, meilleur est le rapport qualit√©/prix.

---

## üîç Sources Tierces de Comparaison

| Source | URL | Focus |
|--------|-----|-------|
| Vellum AI | https://www.vellum.ai/blog/claude-opus-4-5-benchmarks | Analyse Claude 4.5 |
| DataCamp | https://www.datacamp.com/blog/claude-opus-4-5 | Review technique |
| CounselPro | https://www.counselpro.ai/blog/chatgpt-vs-claude-vs-gemini-for-lawyers-financial-review | Legal/Finance |
| Simon Willison | https://simonwillison.net/2025/Nov/18/gemini-3/ | Tests Gemini 3 |
| MarkTechPost | https://www.marktechpost.com/ | Analyses techniques |

---

## ‚ö†Ô∏è Limitations

1. **Benchmarks ‚â† Performance r√©elle:** Les benchmarks mesurent des t√¢ches sp√©cifiques, pas toutes les situations possibles.

2. **√âvolution rapide:** Les scores peuvent changer avec les mises √† jour des mod√®les.

3. **Contexte sp√©cifique:** Un mod√®le "meilleur" en moyenne peut √™tre moins bon pour votre cas d'usage pr√©cis.

4. **Biais de prompt:** Les r√©sultats peuvent varier selon la fa√ßon dont les prompts sont formul√©s.

---

## üìÖ Derni√®re mise √† jour

**Date:** D√©cembre 2025

**Mod√®les couverts:**
- Claude Opus 4.5, Sonnet 4.5, Haiku 4.5
- GPT-5.1, GPT-5.1 Mini, GPT-5 Pro
- Gemini 3 Pro, Gemini 3 Flash

---

## üìù Comment contribuer

Si vous trouvez des erreurs ou avez des sources plus r√©centes:

1. V√©rifiez que la source est officielle ou peer-reviewed
2. Incluez l'URL compl√®te et la date
3. Pr√©cisez le benchmark et le score exact

---

*Ce document est g√©n√©r√© automatiquement par PromptForge et mis √† jour r√©guli√®rement.*
